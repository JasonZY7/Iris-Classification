{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "SSD1wiKRErl2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. DATA PREPARATION"
      ],
      "metadata": {
        "id": "H0E3unZDFWGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the iris dataset\n",
        "iris = load_iris(as_frame=True)\n",
        "df = iris.frame  # 150 rows, 5 columns: 4 features + target\n",
        "\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nFeature columns: {iris.feature_names}\")\n",
        "print(f\"Target classes: {iris.target_names.tolist()}\")\n",
        "\n",
        "# Check for missing values\n",
        "print(f\"\\nMissing values per column:\\n{df.isnull().sum()}\")\n",
        "\n",
        "# Feature ranges per class\n",
        "print(\"\\nFeature ranges by class:\")\n",
        "for i, name in enumerate(iris.target_names):\n",
        "    class_data = df[df['target'] == i]\n",
        "    print(f\"{name}:\")\n",
        "    print(f\"  sepal length: {class_data['sepal length (cm)'].min():.1f} - {class_data['sepal length (cm)'].max():.1f} cm\")\n",
        "    print(f\"  sepal width:  {class_data['sepal width (cm)'].min():.1f} - {class_data['sepal width (cm)'].max():.1f} cm\")\n",
        "    print(f\"  petal length: {class_data['petal length (cm)'].min():.1f} - {class_data['petal length (cm)'].max():.1f} cm\")\n",
        "    print(f\"  petal width:  {class_data['petal width (cm)'].min():.1f} - {class_data['petal width (cm)'].max():.1f} cm\")\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "print(f\"\\nFeatures shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"Class distribution:\\n{y.value_counts().sort_index()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du_TS-VeEzEu",
        "outputId": "45978462-9133-4910-e428-9c396004f279"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (150, 5)\n",
            "\n",
            "Feature columns: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Target classes: ['setosa', 'versicolor', 'virginica']\n",
            "\n",
            "Missing values per column:\n",
            "sepal length (cm)    0\n",
            "sepal width (cm)     0\n",
            "petal length (cm)    0\n",
            "petal width (cm)     0\n",
            "target               0\n",
            "dtype: int64\n",
            "\n",
            "Feature ranges by class:\n",
            "setosa:\n",
            "  sepal length: 4.3 - 5.8 cm\n",
            "  sepal width:  2.3 - 4.4 cm\n",
            "  petal length: 1.0 - 1.9 cm\n",
            "  petal width:  0.1 - 0.6 cm\n",
            "versicolor:\n",
            "  sepal length: 4.9 - 7.0 cm\n",
            "  sepal width:  2.0 - 3.4 cm\n",
            "  petal length: 3.0 - 5.1 cm\n",
            "  petal width:  1.0 - 1.8 cm\n",
            "virginica:\n",
            "  sepal length: 4.9 - 7.9 cm\n",
            "  sepal width:  2.2 - 3.8 cm\n",
            "  petal length: 4.5 - 6.9 cm\n",
            "  petal width:  1.4 - 2.5 cm\n",
            "\n",
            "Features shape: (150, 4)\n",
            "Target shape: (150,)\n",
            "Class distribution:\n",
            "target\n",
            "0    50\n",
            "1    50\n",
            "2    50\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. TRAIN/TEST SPLIT"
      ],
      "metadata": {
        "id": "MA_P-YKRFeuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data: 80% training, 20% testing\n",
        "# Using stratified split to maintain class distribution in both sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set size: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"Test set size: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "print(f\"\\nTraining class distribution:\\n{y_train.value_counts().sort_index()}\")\n",
        "print(f\"\\nTest class distribution:\\n{y_test.value_counts().sort_index()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-X_naE2E33X",
        "outputId": "67c2d564-c485-45e0-ee4d-2640a62e64b7"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 120 samples (80.0%)\n",
            "Test set size: 30 samples (20.0%)\n",
            "\n",
            "Training class distribution:\n",
            "target\n",
            "0    40\n",
            "1    40\n",
            "2    40\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Test class distribution:\n",
            "target\n",
            "0    10\n",
            "1    10\n",
            "2    10\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. MODEL TRAINING"
      ],
      "metadata": {
        "id": "SSnXB2vSFpav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "print(\"\\nTraining Logistic Regression model...\")\n",
        "lr_model = LogisticRegression(max_iter=1000)\n",
        "lr_model.fit(X_train, y_train)\n",
        "print(\"Logistic Regression training complete.\")\n",
        "\n",
        "# Decision Tree Classifier\n",
        "print(\"\\nTraining Decision Tree model...\")\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "print(\"Decision Tree training complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aNOyz0AFkpb",
        "outputId": "6c1aae31-4c0c-41c4-dc41-b158ea6d301a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Logistic Regression model...\n",
            "Logistic Regression training complete.\n",
            "\n",
            "Training Decision Tree model...\n",
            "Decision Tree training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. MODEL EVALUATION"
      ],
      "metadata": {
        "id": "oV9iKv73Foqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "lr_predictions = lr_model.predict(X_test)\n",
        "dt_predictions = dt_model.predict(X_test)\n",
        "\n",
        "# --- Accuracy ---\n",
        "print(\"\\n--- a. ACCURACY ---\")\n",
        "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
        "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
        "\n",
        "print(f\"Logistic Regression Accuracy: {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)\")\n",
        "print(f\"Decision Tree Accuracy:       {dt_accuracy:.4f} ({dt_accuracy*100:.2f}%)\")\n",
        "\n",
        "# --- Classification Reports ---\n",
        "target_names = iris.target_names.tolist()\n",
        "print(\"\\n--- b. CLASSIFICATION REPORTS ---\")\n",
        "\n",
        "print(\"\\n>> Logistic Regression Classification Report:\")\n",
        "print(classification_report(y_test, lr_predictions, target_names=target_names))\n",
        "\n",
        "print(\"\\n>> Decision Tree Classification Report:\")\n",
        "print(classification_report(y_test, dt_predictions, target_names=target_names))\n",
        "\n",
        "# --- Confusion Matrices ---\n",
        "print(\"\\n--- c. CONFUSION MATRICES ---\")\n",
        "\n",
        "lr_cm = confusion_matrix(y_test, lr_predictions)\n",
        "dt_cm = confusion_matrix(y_test, dt_predictions)\n",
        "\n",
        "print(\"\\nLogistic Regression Confusion Matrix:\")\n",
        "print(lr_cm)\n",
        "\n",
        "print(\"\\nDecision Tree Confusion Matrix:\")\n",
        "print(dt_cm)\n",
        "\n",
        "# Create and save confusion matrix heatmaps\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Logistic Regression confusion matrix\n",
        "sns.heatmap(lr_cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=target_names, yticklabels=target_names,\n",
        "            ax=axes[0], cbar=True)\n",
        "axes[0].set_title('Logistic Regression\\nConfusion Matrix', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xlabel('Predicted Label', fontsize=10)\n",
        "axes[0].set_ylabel('True Label', fontsize=10)\n",
        "\n",
        "# Decision Tree confusion matrix\n",
        "sns.heatmap(dt_cm, annot=True, fmt='d', cmap='Greens',\n",
        "            xticklabels=target_names, yticklabels=target_names,\n",
        "            ax=axes[1], cbar=True)\n",
        "axes[1].set_title('Decision Tree\\nConfusion Matrix', fontsize=12, fontweight='bold')\n",
        "axes[1].set_xlabel('Predicted Label', fontsize=10)\n",
        "axes[1].set_ylabel('True Label', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nConfusion matrix heatmap saved as 'confusion_matrix.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egvm8UJrFxa-",
        "outputId": "5a2c6a95-9bc2-424d-99e1-7fc7f71d3927"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- a. ACCURACY ---\n",
            "Logistic Regression Accuracy: 0.9667 (96.67%)\n",
            "Decision Tree Accuracy:       0.9333 (93.33%)\n",
            "\n",
            "--- b. CLASSIFICATION REPORTS ---\n",
            "\n",
            ">> Logistic Regression Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       1.00      0.90      0.95        10\n",
            "   virginica       0.91      1.00      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.97      0.97      0.97        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n",
            "\n",
            ">> Decision Tree Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        10\n",
            "  versicolor       0.90      0.90      0.90        10\n",
            "   virginica       0.90      0.90      0.90        10\n",
            "\n",
            "    accuracy                           0.93        30\n",
            "   macro avg       0.93      0.93      0.93        30\n",
            "weighted avg       0.93      0.93      0.93        30\n",
            "\n",
            "\n",
            "--- c. CONFUSION MATRICES ---\n",
            "\n",
            "Logistic Regression Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  1]\n",
            " [ 0  0 10]]\n",
            "\n",
            "Decision Tree Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  1]\n",
            " [ 0  1  9]]\n",
            "\n",
            "Confusion matrix heatmap saved as 'confusion_matrix.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w10SOTqUHROZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
